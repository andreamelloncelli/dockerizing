
###############################################
## A SPARK standalone cluster
# https://spark.apache.org/docs/latest/spark-standalone.html

master:
    image: pdonorio/spark
    hostname: master
    command: /bootmaster.sh
    environment:
        SPARK_MASTER_HOST: master
    #Â Let other containers slave reach the hadoop master:
    expose:
        - 7077
    ports:
        - 8080:8080
data:
    image: busybox
    volumes:
        - ./data:/data
worker:
    image: pdonorio/spark
    hostname: worker
    command: /bootslave.sh
    # # This will work with docker compose 1.5
    # command: "$${BSWORKER}"
    # #https://github.com/Homebrew/homebrew/issues/41665
    volumes_from:
        - data
    environment:
        SPARK_WORKER_CORES: 2
        SPARK_WORKER_MEMORY: 1g
        SPARK_WORKER_WEBUI_PORT: 8081
    links:
        - master
    ports:
        - 8081:8081

####################################################
#https://hub.docker.com/r/jupyter/pyspark-notebook/
client:
    image: pdonorio/nbspark
    hostname: ipyspark
    environment:
        MASTER: spark://master:7077
        # USE_HTTPS: yes
        PASSWORD: mytest
    ports:
        - 80:8888
    links:
        - master
    volumes_from:
        - data
    volumes:
        - ./data/nbs:/home/jovyan/work

####################################################
